<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="niuoo" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="It is my Blog!">
<meta property="og:type" content="website">
<meta property="og:title" content="niuoo">
<meta property="og:url" content="http://niuoo.github.io/page/2/index.html">
<meta property="og:site_name" content="niuoo">
<meta property="og:description" content="It is my Blog!">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="niuoo">
<meta name="twitter:description" content="It is my Blog!">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://niuoo.github.io/page/2/"/>

  <title> niuoo </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">niuoo</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Develop with pleasure!</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/30/Jdata特征工程分析/" itemprop="url">
                  Jdata特征工程分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-07-30T00:15:05+08:00" content="Jul 30 2017">
              Jul 30 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据介绍">数据介绍</h1>
<p>符号定义： S：提供的商品全集； P：候选的商品子集（JData_Product.csv），P是S的子集； U：用户集合； A：用户对S的行为数据集合； C：S的评价数据。</p>
<p>训练数据部分： 提供2016-02-01到2016-04-15日用户集合U中的用户，对商品集合S中部分商品的行为、评价、用户数据；提供部分候选商品的数据P。 选手从数据中自行组成特征和数据格式，自由组合训练测试数据比例。</p>
<p>预测数据部分： 2016-04-16到2016-04-20用户是否下单P中的商品，每个用户只会下单一个商品；抽取部分下单用户数据，A榜使用50%的测试数据来计算分数；B榜使用另外50%的数据计算分数(计算准确率时剔除用户提交结果中user_Id与A榜的交集部分)。</p>
<p>为保护用户的隐私和数据安全，所有数据均已进行了采样和脱敏。 数据中部分列存在空值或NULL，请参赛者自行处理。</p>
<ol style="list-style-type: decimal">
<li><p>用户数据 user_id 用户ID 脱敏 age 年龄段 -1表示未知 sex 性别 0表示男，1表示女，2表示保密 user_lv_cd 用户等级 有顺序的级别枚举，越高级别数字越大 user_reg_tm 用户注册日期 粒度到天</p></li>
<li><p>商品数据 sku_id 商品编号 脱敏 a1 属性1 枚举，-1表示未知 a2 属性2 枚举，-1表示未知 a3 属性3 枚举，-1表示未知 cate 品类ID 脱敏 brand 品牌ID 脱敏</p></li>
<li><p>评价数据 dt 截止到时间 粒度到天 sku_id 商品编号 脱敏 comment_num 累计评论数分段 0表示无评论，1表示有1条评论， 2表示有2-10条评论， 3表示有11-50条评论， 4表示大于50条评论 has_bad_comment 是否有差评 0表示无，1表示有 bad_comment_rate 差评率 差评数占总评论数的比重</p></li>
<li><p>行为数据 user_id 用户编号 脱敏 sku_id 商品编号 脱敏 time 行为时间<br> model_id 点击模块编号，如果是点击 脱敏 type 1.浏览（指浏览商品详情页）； 2.加入购物车；3.购物车删除；4.下单；5.关注；6.点击</p></li>
</ol>
<p>cate 品类ID 脱敏 brand 品牌ID 脱敏 登录并报名参赛后方可在“数据下载”页面下载数据。</p>
<p>任务描述： 参赛者需要使用京东多个品类下商品的历史销售数据，构建算法模型，预测用户在未来5天内，对某个目标品类下商品的购买意向。对于训练集中出现的每一个用户，参赛者的模型需要预测该用户在未来5天内是否购买目标品类下的商品以及所购买商品的SKU_ID。评测算法将针对参赛者提交的预测结果，计算加权得分。</p>
<h1 id="section">。。。</h1>
<p>用于预测 2016-4-11&lt;=time1&lt;=2016-04-15 用于训练数据确定标签的值 2016-4-06&lt;=time2&lt;2016-04-11 用户构建特征 time3&lt;2016-04-06 features &lt;– ‘select user_id, sum(case when type=2 then 1 else 0 end) as add from JData_Action where time&lt;2016-4-06 group by user_id’</p>
<p>-Xms1024M -Xmx4096M -XX:PermSize=1024M -XX:MaxNewSize=2048M -XX:MaxPermSize=4096M -Xss8192M -XX:StackShadowPages=50</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/12/召回率/" itemprop="url">
                  召回率
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-07-12T22:01:59+08:00" content="Jul 12 2017">
              Jul 12 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/media/14998682171580.jpg"> <img src="/media/14998682636712.jpg"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/06/林轩田机器学习基石笔记/" itemprop="url">
                  林轩田机器学习基石笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-06-06T16:36:53+08:00" content="Jun 6 2017">
              Jun 6 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://github.com/niuoo/machine-learning-foundations/tree/master/foundations" target="_blank" rel="external"><strong>我的课程作业源码github地址</strong></a></p>
<p><a href="https://www.douban.com/doulist/3381853/" target="_blank" rel="external">这位同学的笔记做的很好</a> <img src="/media/14966834620659.jpg"> 知错能改，善莫大焉！:-)</p>
<p><img src="/media/14998352577521.jpg"> <a href="https://www.douban.com/note/319669984/" target="_blank" rel="external">PLA(Perceptron Learning Algorithm)感知机算法有效性证明过程</a>PLA不断进行错误修正的算法，是可以停下来的。可是这个算法有个很大的缺点，因为此算法必须建立在假设线性可分的基础上。如果假设不成立的话，PLA根本跑得停不下来。一开始我们是不会知道PLA能不能停下来的，这个时候可采用Pocket Algorithm，做得还不错。 <img src="/media/14998653580014.jpg"></p>
<div class="figure">
<img src="/media/14999565852705.jpg">

</div>
<p>Hoeffding’s inequality Hoeffding不等式 <img src="/media/15002855220854.jpg"></p>
<p><img src="/media/15002612963279.jpg"> 看到这一点的时候颇为迷惑，B(3,3)=7，B(4,3)是通过复制B(3,3)的一部分得来的。那么为什么α(复制的部分)需要no shatter any 2，其实想想假如 α shatter 2了，也就是B(3,2)，那么复制后，加上<span class="math">\(x_4\)</span>总共8种情形，必然是shatter 3 了，因为<span class="math">\(8 = 2^3\)</span>。 所以，得到：B(4,3) = 2*a + b &lt;= B(3,3) + B(3,2). 对于任意N &gt; k, 利用上述思路，可以证明 B(N,k) &lt;= B(N-1, k) + B(N-1,k-1). 有了递推不等式，通过数学归纳法，可证明下面的Bounding Function (N &gt; k) : <img src="/media/15002711060448.jpg"></p>
<p>归纳法证明过程如下： <img src="/media/15002882090009.jpg"></p>
<p>为什么机器学习是有效的？ <img src="/media/15002851562508.jpg"></p>
<div class="figure">
<img src="/media/15008820248463.jpg">

</div>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/19/做个机器学习Python调包侠/" itemprop="url">
                  做个机器学习Python调包侠
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-19T14:39:55+08:00" content="May 19 2017">
              May 19 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>算法</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/14/Recommender-Systems-推荐系统/" itemprop="url">
                  Recommender Systems 推荐系统
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-14T13:06:31+08:00" content="May 14 2017">
              May 14 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>推荐系统是机器学习的一个重要应用。很多团队都致力于建立更好的推荐系统，比如亚马逊、Netflix、eBay或者苹果公司的iTunes Genius做的事情，有很多网站或者系统试图向用户推荐新产品，亚马逊向你推荐新书，Netflix想你推荐新电影，诸如此类。而这些推进系统可能会看看你以前购买过什么书，或者以前你给哪些电影进行过评分，这些系统贡献了现今亚马逊收入的相当大一部分，而Netflix，他们向用户推荐的电影占了用户观看电影的大部分。推荐系统，其表现的一些改进就能带来显著且即刻产生的影响，这些影响关系到许多公司的最终业绩。<br>在机器学习中，特征量是重要的，选择的特征对学习算法的表现有很大影响。在机器学习领域，有这么一个宏大的想法，就是对于一些问题，可能不是所有问题，但是对于一些问题而言，存在一些算法，能试图自动地学习到一组优良的特征量，而不用人为动手设计或者手动编写特征。<br>有些情况，或许能够采用一种算法，来学习到使用什么特征量，而推荐系统，就是这种情形的一个例子，当然还有其他很多例子。通过学习推荐系统，我们能够对这种学习特征量的想法有一点了解，我们至少可以通过这个例子，来了解机器学习中的这种big idea。</p>
<h1 id="推荐系统算法">推荐系统算法</h1>
<h3 id="推荐系统在做什么">推荐系统在做什么</h3>
<p>如下图所示，给定这些r(i,j)与y(i,j)数据，其中r(i,j)表示用户j给电影i是否打分，y(i,j)表示用户j给电影i所打的分数，然后浏览全部数据，关注所有没有电影评分的地方，并试图预测这些带问号的地方，应该是什么数值。如下图，前三部电影可能是浪漫爱情电影，后两部是动作片，然后Alice和Bob看起来喜欢爱情片，我们预测Alice也许会给电影Cute puppies of love打分5，Bob给电影Romance forever打分4.5，推荐系统就是通过填充这些数值，然后推测用户更喜欢什么电影，并进行相应推荐。有一些电影，还有一些用户，用户给一些电影进行了评价打分，推荐系统所做的事情就是，通过这些评分，预测用户会怎样给还没看过的电影打分。<br><img src="/media/14947442269252.jpg"></p>
<h2 id="基于内容的推荐-cotent-based-recommendations">基于内容的推荐 Cotent Based Recommendations</h2>
<p>注意看<span class="math">\(x^{(i)}\)</span>，它表示某部电影是浪漫和动作片程度的多少。算法的目的是学到每个用户喜爱浪漫电影和动作电影程度的变量<span class="math">\(θ^{(j)}\)</span>，然后使用<span class="math">\((θ^{(j)})^Tx^{(i)}\)</span>就可以预测第j个用户可能给第i部电影所打的分数。<br><img src="/media/14947615593109.jpg"></p>
<p>学习每个<span class="math">\(θ^{(j)}\)</span>的值是一个基本的线性回归问题，算法的目的是为了学习到<span class="math">\(θ^{(j)}\)</span>使得下面的损失函数的值最小。但是这个又和我们以前所学习的线性回归问题不同，因为在这里，每个用户的<span class="math">\(θ^{(j)}\)</span>值是不同的，每个用户都有单独属于自己的<span class="math">\(θ^{(j)}\)</span>值，这就使得个性化推荐成为现实。我们可以把对每个观众打分的预测，当成一个独立的线性回归问题。<br><img src="/media/14947649924645.jpg"></p>
<p>优化目标就是图上的公式，对于每一个用户，我们都进行计算。<span class="math">\(θ^{(n_u)}\)</span>表示第n个用户的θ值。<br><img src="/media/14947714065234.jpg"></p>
<p>梯度下降过程如下。 <img src="/media/14947721242572.jpg"> 以上，就是运用线性回归的变体，来预测不同用户对不同电影的评分值。这种做法，叫做『基于内容的推荐』，因为我们具有电影的特征量<span class="math">\(x^{(i)}\)</span>，来表示电影内容的属性，比如电影爱情的成分是多少，动作的成分是多少。但是实际上，我们很少知道所有电影的特征，或者我们要卖的产品有什么特征，所以接下来，我们介绍不具有这些内容特征时，该如何进行推荐。</p>
<h2 id="协同过滤-collaborative-filtering">协同过滤 Collaborative Filtering</h2>
<p>协同过滤，可以自行学习所要使用的特征。<br>如下图所示，假如用户告诉了他们的偏好，那么我们可以知道每个<span class="math">\(θ^{(j)}\)</span>的值，来学习到<span class="math">\(x^{(i)}\)</span>的值。<br><img src="/media/14947754778241.jpg"></p>
<p>根据用户的偏好，学习电影的特征指数，优化目标如下图所示：<br><img src="/media/14947761941215.jpg"></p>
<p>如下图所示，把二者合并起来，就是协同过滤了。根据每个用户对多部电影的评分，以及每部电影由不同用户的评分，可以反复进行这样的过程，来估计出θ和x。协同过滤算法指的是，当你执行这个算法时，你通过一大堆用得到数据，这些数据实际上在高效地进行了协同合作，来得到每个人对电影的评分值。只要用户对某几部电影进行评分，每个用户就都在帮助算法，更好的学习出特征，这些特征又可以被系统运用，为其他人做出更准确的电影预测。协同的另一层意思是，每位用户，都在帮助系统，学习出更好的特征，这就是协同过滤。<br><img src="/media/14947774794944.jpg"></p>
<h2 id="协同过滤算法-collaborative-filtering-algorithm">协同过滤算法 Collaborative Filtering Algorithm</h2>
<p>把上面讲的两个损失函数合并起来，就是我们希望优化的新的代价函数，新的代价函数是同时关于θ和x的函数，二者同时更新，最终是的J最小。<br><img src="/media/14947796300697.jpg"></p>
<p>协同算法步骤：</p>
<ul>
<li><p>首先将会把θ和x初始化为小的随机值，这有点儿像神经网络训练，所有神经网络的权值参数，我们也是用小的随机数值来初始化的。协同过滤的初始化和神经网络初始化一样，也需要打破对称symmetry breaking. <img src="/media/14947804720110.jpg"></p></li>
<li><p>使用梯度下降，或者其他的高级优化算法，把代价函数最小化，如果求导，梯度下降更新写出来的结果如图中第2项所示。通过梯度下降，我们同时更新θ和x的值。<br> <img src="/media/14947802773743.jpg"></p></li>
<li><p>根据以上求出的θ和x的值，我们就可以预测每一个用户了。</p></li>
</ul>
<p>以上就是协同过滤算法的具体过程。通过协同过滤算法，可以同时学习几乎所有电影的特征x，和所有用户的参数θ，然后有很大机会，能对不同用户会如何评价他们尚未评分的电影，做出相当准确的预测。</p>
<h3 id="低秩矩阵分解-low-rank-matrix-factorization">低秩矩阵分解 Low Rank Matrix Factorization</h3>
<p>通过向量化的计算，来对所有的用户和所有的电影，进行评分计算。 <img src="/media/14947819692395.jpg"></p>
<h3 id="向用户做出相关推荐">向用户做出相关推荐</h3>
<p>根据协同过滤算法，当给出一件产品时，可以找到与之相关的其它产品，再例如，一位用户最近看上一件产品，看有没有其它相关的产品，你可以推荐给他。<br>怎么给用户进行相关推荐呢？请看下图。用户曾给电影i打过高分，我们根据算法得到<span class="math">\(x^{(i)}\)</span>，电影i的特征指数，那么我们就找到距离<span class="math">\(x^{(i)}\)</span>最近的几个电影，推荐给用户。<span class="math">\(||x^{(i)}-x^{(j)}||\)</span>表示的是<span class="math">\(x^{(i)}与x^{(j)}\)</span>的欧式距离。<br><img src="/media/14947831732793.jpg"></p>
<h3 id="预处理步骤-均值归一化">预处理步骤-均值归一化</h3>
<p>求出每一个电影的平均分μ，然后每个打分减去该电影的平均分，每一行的总和其实还是0.我们这样做均值归一化了。当我们在预测具体某个用户对某个电影评分的时候，还是要把平均分μ加上的。对于某个用户从来没评论过任何电影，那么也默认他的评分是平均分水平。 <img src="/media/14947848429032.jpg"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/14/Dimensionality-Reduction-维度约减/" itemprop="url">
                  Dimensionality Reduction 主成分分析PCA
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-14T00:30:13+08:00" content="May 14 2017">
              May 14 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>使用Dimensionality Reduction-维数约减，一般是为了数据压缩，减少内存和硬盘空间存储，并提高算法速度。在特征降维的方法中，PCA(Principle Component Analysis)是最为经典和实用的特征降维技术，特别是在辅助图像识别方面有突出表现。 特征降维是无监督学习的另一个应用。降维/压缩问题是选取数据具有代表性的特征，在保持数据多样性(Variance)的基础上，规避掉大量的特征冗余和噪声，不过这个过程也很有可能会损失一些有用的模式信息。经过大量的实践证明，相较于损失的少部分模型性能，维度压缩可节省大量用于模型训练的时间，使得模型综合效率变得更高。</p>
<p>在实际项目中，我们会得到特征维度非常高的训练样本，有的特征向量之间是有关系的，比如预测房价的时候，得到的房子长度inches英寸和cm厘米，它们两个是线性相关的，所以有一个信息是冗余的，就可以去掉一个。又如下图所示，数据集中在一个平面Z附近，所以就可以把3D的数据降维成2D。 <img src="/media/14945865066705.jpg"></p>
<h1 id="主成分提取principal-component-analysis-problem-formulation">主成分提取(Principal Component Analysis problem formulation)</h1>
<p>对于降维问题，目前最流行的，最常用的算法就是PCA主成分分析法。 PCA做的就是，寻找一条直线，或者面，或者诸如此类，比起特征向量低维的空间，对数据进行投影，并且最小化投影距离，也就是数据点和投影后的点之间的距离。另外，在寻找vectors时，对于所有的数据集和特征向量，都是同等对待的。一般用投影的数据，当做被降维的数据使用。 <img src="/media/14946121526774.jpg"></p>
<p>关于上图的左边，注意区别PCA和线性回归，两个截然不同的概念。 <img src="/media/14946125078718.jpg"></p>
<h3 id="数据预处理-data-preprocessing">数据预处理 Data preprocessing</h3>
<p>在使用PCA之前，我们通常会有一个<strong>数据预处理</strong>的过程，就是对数据进行均值归一化。 <img src="/media/14946138068434.jpg"></p>
<h3 id="pac算法-principal-component-analysispca-algorithm">PAC算法 Principal Component Analysis(PCA) algorithm</h3>
<p>首先要做的是计算出∑协方差矩阵。<span class="math">\(∑=\frac{1}{m}\sum^m_{i=1}(x^{(i)})(x^{(i)})^T\)</span>,∑(Sigma)是个n×n的矩阵，因为<span class="math">\(x^{(i)}\)</span>是个n×1的向量，<span class="math">\((x^{(i)})^T\)</span>是个1×n的向量，两个向量相乘就是n×n的矩阵了。另外，协方差均值∑(Sigma)总满足一个数学性质，称为对称正定(symmetric positive definite)。这块线性代数的知识不懂，不过不必介意，反正就是这么求的，代码也不长。记得线性代数课中曾经讲到如何求特征向量什么的，现在用到了吧，忘了吧？呵呵^_^<br>svd(singular value decomposition)表示奇异值分解，svd(matlab奇异值分界的库函数,eig(Sigma)也有同样功能)将输出三个矩阵，分别是U、S、V，真正需要的是U矩阵，U矩阵也是个n×n矩阵。如果我们想将数据降维到k-dimensions的话，我们只需提取前k列向量，也就是用来投影数据的k个方向。 <img src="/media/14946971878921.png"> <span class="math">\(U_{reduce}\)</span>指U取前k列得到的n×k矩阵，X是训练集中的样本或者交叉训练集中的样本或者是测试集样本，然后Z矩阵的表达，是使用Z=<span class="math">\(U_{reduce}^TX\)</span>，也就是k×n矩阵和n×1矩阵相乘，所以Z就是k维的向量。 <img src="/media/14946981115876.jpg"></p>
<p>总结一下PAC的全过程，如下图所示。 <img src="/media/14946983615287.jpg"></p>
<h1 id="还原压缩数据">还原压缩数据</h1>
<p>压缩数据时，我们也许会把一千维的数据压缩到只有一百个维度，既然我们可以用算法如此压缩数据，那么也应该有办法，可以从压缩过的数据，近似地回到原始高维度的数据。假设有一个已经被压缩过的<span class="math">\(z^{(i)}\)</span>，它有100维度，怎样使它回到其最初的表示<span class="math">\(x^{(i)}\)</span>，也就是压缩前的1000维的数据呢？</p>
<p>呵呵，这一块先不写了。以后再补上。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/05/Anomaly-Detection-反常检测/" itemprop="url">
                  Anomaly Detection 反常检测
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-05T23:03:49+08:00" content="May 5 2017">
              May 5 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>异常检测最常用的应用是欺诈检测。系统的用户都在从事不同的活动，可以对不同的用户活动计算特征变量，然后可以建立一个模型，用来表示用户表现出各种行为的可能性，也就是用户行为对应的特征向量出现的频率。</p>
<h4 id="异常检测例子">异常检测例子</h4>
<ul>
<li><p>某个用户在网站上行为的特征变量，也许<span class="math">\(x_1\)</span>是用户登陆的频率，<span class="math">\(x_2\)</span>是用户访问某个页面的次数或者交易次数，<span class="math">\(x_3\)</span>是用户在论坛上发帖的次数，<span class="math">\(x_4\)</span>是用户的打字次数，有些网站是可以记录用户每秒打了多少个字母的，因此可以根据这些数据建一个模型p(x)，可以用它来发现网站上行为奇怪的用户，只需要看哪些用户的p(x)概率小于ε，接下来，你拿来这些用户的档案，做进一步的筛选，或者要求这些用户，验证他们的身份，从而让网站可防御异常行为或者欺诈行为。这样的过程，可以找到行为不正常的用户，而不只是有欺诈行为的用户，也不只是那些被盗号的用户或者有行为比较搞笑的用户，而是行为不寻常的用户。这就是许多在线购物网站，常用来识别异常用户的技术。这些用户行为奇怪，可能表示他们有欺诈行为，或者是被盗号。</p></li>
<li><p>工业生产领域，发现异常的产品，然后要求进一步细查这些产品的质量。比如飞机引擎异常检测。</p></li>
<li><p>数据中心的计算机监控。假如，管理一个计算机集群，或者一个数据中心，其中有许多计算机，那么我们可以为每台计算机计算特征变量，也许某些特征衡量计算机的内存消耗，或者硬盘访问量，CPU负载，或者更加复杂的特征，比如CPU负载于网络流量的比值。建立p(x)模型，找到异常情况不正常工作的计算机，也许它即将停机，因此可以有求系统管理员查看其工作状况。目前这种技术实际正在被各大数据中心使用，用来检测大量计算机可能发生的异常。 <img src="/media/14948382044224.jpg"></p></li>
</ul>
<h3 id="高斯分布-gaussian-normal-distribution">高斯分布 Gaussian (Normal) Distribution</h3>
<p>高斯分布也称为正态分布。μ是均值，代表钟形曲线的对称轴，σ标准差确定了高斯分布概率密度函数的宽度，<span class="math">\(σ^2\)</span>表示方差。 <img src="/media/14948391530737.jpg"></p>
<p>高斯分布的例子，曲线的阴影部分面积是1，这是概率密度函数的特性。注意看高度和宽度和对称轴。 <img src="/media/14948397775893.jpg"> 参数估计问题。其实这里也是极大似然估计。 注意看下图中对μ和<span class="math">\(σ^2\)</span>的确定。 <img src="/media/14948406033181.jpg"></p>
<h3 id="异常检测算法">异常检测算法</h3>
<p>这里运用高斯分布开发异常检测算法。步骤如图所示：</p>
<ol style="list-style-type: decimal">
<li>首先选择特征，找出可能可以看出他们的反常和欺诈行为的特征<span class="math">\(x_i\)</span>，这个特征值或者过大或者过小，尽可能找出那些能够描述数据相关的属性特征；</li>
<li>计算均值和方差；</li>
<li>计算p(x)，如果p(x)&lt;ε,则定为异常。 <img src="/media/14948421441058.jpg"> 如下图，分布在桃红色区域的样本，就是异常的样本。<br><img src="/media/14948440235452.jpg"></li>
</ol>
<h3 id="分配样本数据">分配样本数据</h3>
<p>如果有10000个好的正常的引擎，20个异常的引擎，那么会分配6000个好的引擎作为训练集，2000好的引擎和10个不正常的引擎作为交叉验证集，剩下的2000好的引擎和10个不正常的引擎作为测试集。一般是6:2:2作为Training set:CV:Test<br><img src="/media/14948623383598.jpg"></p>
<h3 id="如何评估异常检测系统">如何评估异常检测系统</h3>
<p>对于异常检测系统，分类准确率不是一个好的评估度量方式。因为如果出现数据非常偏斜，异常数据非常少，我们直接预测所有样本都是正常的，那么这时候准确率还是很高的，但是显然这不是一个好的做法。那么用什么评价度量好呢？取而代之的是，我们应该算出真阳性、假阳性、假阴性和真阴性的比率。我们也可以算出查准率与召回率的比值；或者算出<span class="math">\(F_1-\)</span>积分，通过一个很简单的数字来表现出查准和召回的大小。通过这些方法，就可以较公平地评价异常检测算法在交叉验证和测试集样本中的表现。<br> 那么如何确定阈值ε呢？可以试试多个不同的ε取值，然后选出一个使得<span class="math">\(F_1-Score\)</span>值最大的那个ε，也就是在交叉验证集中表现最好的ε。<br><img src="/media/14948651051920.jpg"></p>
<h3 id="anomaly-detection-vs.supervised-learning">Anomaly detection vs. supervised learning</h3>
<p>那么我们什么时候应该用异常检测，什么时候用监督学习分类算法呢？在异常检测算法中，我们只有一小撮正(异常)样本，因此算法不可能从这些正样本中学出太多东西，因此取而代之的是我们使用一组大量的负(正常)样本，这样样本就能学到更多，或者能从大量的负样本中学出p(x)模型，另外会预留一小部分正样本来评价算法，既用于交叉验证集，也用于测试集。而对于垃圾邮件的样本，我们能得到绝大多数不同类型的垃圾邮件，因为我们有大量的垃圾邮件样本的集合，这就是为什么我们通常把垃圾邮件问题看作是监督学习问题的原因。<br>请看下图： <img src="/media/14949132950585.jpg"></p>
<h2 id="关于特征变量的选择">关于特征变量的选择</h2>
<p>对于异常检测算法效率影响最大的因素之一是使用什么特征变量，选择什么特征变量来输入异常检测算法。</p>
<h4 id="处理不符合高斯分布的特征">处理不符合高斯分布的特征</h4>
<p>在MATLAB中绘制直方图的函数是hist，如果画出来的柱状图近似像高斯分布，那么就可以很放心地把它们送入学习算法了，但如果画出来的图像如下图中的左下角图像，分布很不对称，峰值非常偏向一边，类似高斯分布图像的右半边，通常直接这样使用数据，算法也会运行很好，但是如果使用一些方法使得数据更像高斯分布的话，算法会工作的更好。对于左下角图像，就可以进行取对数log(x)的转换，结果就很像高斯分布了。<br><img src="/media/14949358396911.jpg"></p>
<h4 id="如何得到异常检测的特征变量">如何得到异常检测的特征变量</h4>
<p>通过误差分析步骤。如果最终表现不理想，对于很多正样本和负样本都有很大的p(x)的值，那么我们最好还是多引入其它的特征，以便于更好的区分出正样本和负样本。 <img src="/media/14949381932356.jpg"></p>
<h2 id="多元高斯分布-multivariate-gaussian-distribution">多元高斯分布 Multivariate Gaussian Distribution</h2>
<p><img src="/media/14949427576171.jpg"> 多元高斯分布模型和原始高斯分布模型的关系： <img src="/media/14949431790982.jpg"></p>
<h3 id="高斯分布模型-vs-多元高斯分布">高斯分布模型 VS 多元高斯分布</h3>
<p>原始的高斯分布模型使用的更多，但是多元高斯分布可以自动捕获不同特征变量之间的相关性。但是原始模型也有其他很重要的优势，一个很重要的优势，就是运算量很小，如果n的值非常大，也就是说特征变量很多的情况，即使n=100,000，原始模型都可以很好的运行。但是对于多元模型，计算∑的逆矩阵，∑是个n*n的矩阵，也就是100,000乘100,000的矩阵，那么这个计算量会非常大，所以多元模型不是n很大的情况。另外，对于原始的模型，训练集很小也就是m相对小的情况下，它也能运行的还可以，但是多元模型必须要求m&gt;n，样本的数量要大于特征变量的数量，因为如果m小于等于n，那么∑矩阵是不可逆的，是奇异矩阵，这种情况下，不能使用多元模型。一个合理的经验法则，m大于等于n的10倍的时候，再使用高斯模型。<br> 一般情况下，原始模型比较常用，如果需要捕捉特征变量之间的相关性，一般人都会手动增加这样的额外特征变量，来捕捉特定的不正常的值的组合，但是在训练集m很大，n不太大的情况，那么多元高斯模型是值得考虑的，或许可以运行得更好，还可以帮忙省去为了捕捉不正常的特征值组合而手动建立额外特征变量所花费的时间。<br> 另外，如果协方差矩阵∑是不可逆的，奇异的，那么一般只有两种情况:1.没有满足m&gt;n；2.有冗余的特征变量，就是不小心把一个特征变量复制了两份，或者是高度冗余的特征变量，如<span class="math">\(x_3=x_4+x_5\)</span>，那么<span class="math">\(x_3\)</span>就不含有额外的信息，也是冗余。所谓冗余的特征变量，也就是线性相关的特征变量。 <img src="/media/14950095213212.jpg"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/05/无监督式学习/" itemprop="url">
                  无监督式学习之K-means
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-05T23:03:18+08:00" content="May 5 2017">
              May 5 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>无监督学习算法，就是从未标记的数据中进行学习。 <img src="/media/14944286743216.jpg"></p>
<ul>
<li>组织大型计算机集群，并试图找出那些机器趋向于协同工作，如果把这些机器放在一起，就可以让数据中心更高效工作。</li>
<li>社交网络里面也有，区分哪些用户之间是很亲密，哪些用户之间仅仅是认识。</li>
<li>根据商业系统中的数据，细分市场，然后把客户再分到不同的细分市场中。</li>
<li>分析星云的状态。</li>
</ul>
<h1 id="聚类问题clustering-k-means-algorithm">聚类问题(Clustering) K-means Algorithm</h1>
<p>有一堆无标签的数据，K-means能够自动的把这些数据分成有紧密关系的子集或者簇，是现在最为广泛运用的聚类方法。</p>
<ul>
<li><p>首先，要确定分类需要几个簇，也就是K的大小。 <img src="/media/14944822633878.jpg"></p></li>
<li><p>随机初始化K个簇中心，分别是<span class="math">\(μ_1,μ_2,…,μ_K ∈ R^n\)</span>(n是特征向量的纬度)。 <img src="/media/14944860345126.jpg"></p></li>
<li>不断重复一下步骤：
<ol style="list-style-type: decimal">
<li>找出数据<span class="math">\(x^{(i)}离哪个簇中心最近，用c^{(i)}记录簇中心的索引，c^{(i)}= min_k||x^{(i)}-μ^{(k)}||^2\)</span>。m是训练数据的总个数。<span class="math">\(c^{(i)}\)</span> = index of cluster(1,2,…,k) to which example <span class="math">\(x^{(i)}\)</span>is currently assigned。这一步就是把m个<span class="math">\(x^{(i)}\)</span>划分给各自所属的聚类中心。</li>
<li>根据当前分开的簇，再重新计算每个簇的簇中心。例如 <span class="math">\(c^{(1)}=2,c^{(5)}=2,c^{(6)}=2,c^{(10)}=2\)</span>，那么<span class="math">\(μ_2=\frac{1}{4}[x^{(1)}+x^{(5)}+x^{(6)}+x^{(10)}]\)</span>。如果某个簇里面没有分配任何1个点，那么就把这个簇中心移除掉，或者重新随机找一个聚类中心，但是直接移除是更为常见的方法。</li>
<li>我们优化的目标是找到最好的<span class="math">\(μ_1,…μ_K\)</span>,使得<span class="math">\(J(c^{(1)},…,c^{(m)},μ_1,…μ_K)=\frac{1}{m}\sum_{i=1}^m||x^{(i)}-μ_{c^{(i)}}||^2\)</span>取得最小值，同时J是一直收敛的。 <img src="/media/14944823083506.jpg"></li>
</ol></li>
</ul>
<h4 id="局部最优解">局部最优解</h4>
<p>另外，局部最优解是可能产生的，有时候2个聚类中心会在一起，卡在了局部最优。如下图所示，右下角的2个函数图像，表示了2种不同的局部最优。 <img src="/media/14944905514428.jpg"> #### 解决局部最优 为了让K-means方法找到较好的局部最优解或者全局最优解，我们可以尝试多次随机的初始化来保证我们最终能得到一个足够好的结果，而不仅仅初始化一次K-means，就希望得到很好的结果。特别是K处于2到10之间的话，聚类数相对较小的体系里，多次随机初始化效果会非常好，会有较大的影响。但是如果K的值几百上千的话，很可能初次随机初始化就得到很好的结果，多次随机初始化也许会得到稍微好一点的结果，但是不会好太多。 <img src="/media/14944862061717.jpg"></p>
<p>看下图的右边，是一个市场细分的例子，根据数据，将市场分为3个部分，然后区别对待三类不同的顾客群体，更好的适应他们不同的需求，为大中小号3种聚类的用户，设计更合身的S,M,L尺码的衣服。 <img src="/media/14944871641347.jpg"></p>
<h4 id="关于聚类数目k的选取">关于聚类数目K的选取</h4>
<p>关于K应该取什么值，这个问题没有非常标准的解答，或者能自动解决他的方法。目前用来决定聚类数目最常用的方法仍然是通过看可视化的图，或者看聚类算法的输出结果，或者通过其他一切东西来手动选择聚类的数目。嘿嘿，就通过洞察力决定呗。 一般情况下使用肘部法则，但是不用期待表现很好。更多情况下，选择聚类数目的更好方法是，去问一下运行K-means是为了什么目的，然后想想聚类的数目是多少，才适合K-means聚类的后续目的。</p>
<ol style="list-style-type: decimal">
<li><p>肘部法则(Elbow method) 在选择聚类数目K的时候，我们可以使用下肘部方法，如果图像如下图左边的曲线，折点非常明显，那么选择肘点K是个很好的方式，但是如果图像如下图右边所示，那么选取哪个数目，则看起来非常困难。肘部方式，我们可以使用，但是很多时候，往往得不到左图那种有个明显的折点的情况，所以此方式值得尝试，但是我们也不要太期待。 <img src="/media/14944940159311.jpg"></p></li>
<li><p>看不同的聚类数量能为后续下游的目的提供多好的结果。从生意的角度来选择聚类数量，如下图，生产5种大小的T恤可以更加适合顾客，但是3种T恤的话，公司也可以降低成本，更便宜的卖给更多的顾客，因此T恤销售业务的观点，可能会提供一个决定采用3个类还是5个类的方法。 <img src="/media/14944958853442.jpg"></p></li>
</ol>
<h3 id="使用k-means进行图像压缩">使用K-means进行图像压缩</h3>
<p><img src="/media/14966526213973.jpg"> 以上图片是一个使用K-means方法压缩图片的例子。原始图片为128×128像素，每个像素是24位bit长度，每8位表示红绿蓝(red,green,blue)的强度，即RGB编码。原始图片有数千种颜色，现在我们需要将颜色减少到16种。原始图片的存储空间为128×128×24 = 393,216 bits，经过压缩后，所需的存储空间为16×24 + 128×128×4 = 65,920 bits。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/05/Support-Vector-Machines/" itemprop="url">
                  Support Vector Machines
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-05T23:02:21+08:00" content="May 5 2017">
              May 5 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong><a href="http://blog.csdn.net/sealyao/article/details/6442403" target="_blank" rel="external">SVM中的数学和算法</a></strong> 关于支持向量机，这里有<a href="https://www.zhihu.com/question/21094489" target="_blank" rel="external">一个比较有意思的讲解</a>，还有这里<a href="https://www.youtube.com/watch?v=3liCbRZPrZA" target="_blank" rel="external">一个小视频</a>。<br>SVM是数据挖掘里面很重要的算法，我们有时会把SVM看做是一个大间距分类器Large Magin Intuition。SVM Decision Boundary具有鲁棒性，因为它努力用一个最大间距，来分离样本。<br>有个小的知识点，向量内积以及<a href="http://www.cnblogs.com/vive/p/4563803.html" target="_blank" rel="external">证明</a></p>
<h1 id="线性核函数">线性核函数</h1>
<p>SVM线性核函数，就是SVM不使用核函数。其实是在逻辑回归的基础上进行稍微变化而成的。<br><img src="/media/14943143749438.jpg"></p>
<p>使用SVM软件包来确定参数θ的时候，我们需要指定常数C，C值如果太大，那么就会过拟合，效果不好。如以下示图，注意看左下角那个红叉叉，如果C太大的时候，决策边界就会是斜着的那条很线，这样并不好: <img src="/media/14943142227688.jpg"></p>
<h1 id="kernels">Kernels</h1>
<p>构造非线性复杂的分类器，我们用“Kernels函数”来达到此目的。<br>先来看一张图，如果决策分界是曲线的时候，那么就会有多项式特征变量的出现，如果不进行变化，就直接去求解，那么运算量是非常大的，有太多的高阶项需要被计算，所以我们需要通过其他方式来构造特征变量，来嵌入到假设函数中：<br><img src="/media/14943156955239.jpg"></p>
<p>Kernels核函数有很多，我们用的最多的是高斯核函数(Gaussian kernel)，$ f_i=exp{ }$ 其中 <span class="math">\(l^(i) =x^(i) ，x^(i)\)</span>表示m个训练数据的第i个样本，高斯核函数描述了某个样本和其他样本的距离程度。这个函数类似高斯分布，因此称为高斯核函数。也叫做径向基函数(Radial Basis Function 简称RBF)。它能够把原始特征映射到无穷维。 <img src="/media/14943147936462.jpg"></p>
<p>看下面这张图，可以更加理解高斯核函数的作用，注意看图中的红色大圈，如果<span class="math">\(f_1≈1,f_2≈0,f_3≈0\)</span>，那么证明这个点离<span class="math">\(l^(1)\)</span>很近，y=1。图中训练出的θ值，表明了红圈内是预测y=1，红圈外是y=0，即离点<span class="math">\(l^(1),l^(2)\)</span>都很远。这就是我们如何通过标记点以及核函数，来训练出非常复杂的非线性决策边界的方法。</p>
<div class="figure">
<img src="/media/14943222658500.jpg">

</div>
<p>高斯核函数的损失函数如下图所示，不过这些我们自己平时直接使用优化好的SVM包，并不需要关心这些细节，这些都是内部优化好的，不需要来定义。 <img src="/media/14943195312828.jpg"></p>
<p>在使用高斯核函数的时候，我们需要选择<span class="math">\(σ^2\)</span>，如果<span class="math">\(σ^2\)</span>偏大我们就会得到一个较大误差较低方差的分类器，高斯核函数返回的是(0,1)区间的实数。另外，在使用核函数的时候，进行数据归一化也是很必要的，因为如果不进行归一化，那么值比较大的特征向量会占据很大的地位，弱化其他特征向量的影响，这是不公平的。 <img src="/media/14943198501799.jpg"></p>
<p>支持向量机算法的核函数必须满足莫塞尔定理“Mercer’s Theorem”。对于其他的核函数，此处不做过多介绍。这里有个<a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988406.html" target="_blank" rel="external">核函数的介绍</a></p>
<h1 id="如何选择使用何种算法呢">如何选择使用何种算法呢</h1>
<ol style="list-style-type: decimal">
<li>如果特征向量的个数很大,而训练集很小时，我们通常使用逻辑回归，或者使用SVM线性核函数。因为没有足够的数据来拟合非常复杂的非线性函数。</li>
<li>如果特征向量很小，而训练数据量是中等大小，那么核函数表现就可以很好。<br></li>
<li>如果如果特征向量很小，而训练数据量巨大，那么高斯核函数就会运行很慢，这种情况下，可以尝试手动建立更多的特征变量，然后使用逻辑回归或者SVM线性核函数。</li>
</ol>
<div class="figure">
<img src="/media/14943200907676.jpg">

</div>
<p>以上，第2种，例如，特征向量为1000左右，训练集是10,000的情况下，高斯函数的支持向量机会表现的非常突出。另外第1种和第3种情况，其实使用逻辑回归和SVM线性核函数效果都差不多。<br>SVM是凸优化的，所以局部最优，就是全局最优了。</p>
<p>在使用SVM软件包的时候，需要我们自己按照需求，配置以下参数：<br><img src="/media/14943202565702.jpg"></p>
<p>多种分类时：<br><img src="/media/14943205457069.jpg"></p>
<p>其实呢这课，我没怎么看懂，向量内积怎么使用我也不知道，SVM算法怎么使用倒是有个模糊的印象，但是具体内部的算法原理，没搞太明白，不知道最后的决策边界怎么产生的最大边距。这篇SVM我写的好吃力啊，重新刷斯坦福视频的时候居然看不懂了，真是……，不过还好最后看的自己觉得明白了，就先记录下来。吃力。</p>
<p>练习题中，垃圾邮件分类器，采用SVM线性核函数。通过训练集，训练出字典表中每个单词的权重(就是θ参数)。进行垃圾邮件分类时，是需要对邮件内容进行预处理的，比如网址啊，钱啊，之类的，都会用一个单词或者符号代替，出现的哪些单词(当然最后都向量化数字处理了，类似于x = [ 0 0 0 0 1 0 0 0 … 0 0 0 0 1 … 0 0 0 1 0 ..]，x的长度是字典长度，数据1表示出现了这个单词)，最后带入我们的式子<span class="math">\(θ^TX\)</span>里面，可进行是否垃圾邮件的预测，如果大于等于0，就是垃圾邮件，小于0，是正常邮件。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/04/神经网络初探/" itemprop="url">
                  神经网络初探
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-05-04T14:14:20+08:00" content="May 4 2017">
              May 4 2017
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>神经网络是当今最强大的学习算法之一，自动驾驶对周围景物的识别，就用到了神经网络。<br>我们以下讲述，神经网络在分类问题中的应用，在给定训练集下，为神经网络拟合参数的学习方法。<br><span class="math">\(\begin{align*} a_1^{(2)} = g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3) \newline a_2^{(2)} = g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3) \newline a_3^{(2)} = g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3) \newline h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)}) \newline \end{align*}\)</span><br>在整个神经网络算法过程中，我们的最终目标是找到最佳的Θ矩阵中的权值。<br><img src="/media/14943440970717.jpg"></p>
<h1 id="神经网络的损失函数">神经网络的损失函数</h1>
<p>其中逻辑回归的损失函数为：<br><span class="math">\(J(\theta) = - \frac{1}{m} \sum_{i=1}^m [ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2\)</span><br>神经网络的损失函数在逻辑回归的基础上，稍微复杂了一点儿：<br><span class="math">\(\begin{gather*} J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2\end{gather*}\)</span></p>
<ul>
<li>L = 神经网络的层数。<br></li>
<li><span class="math">\(s_l\)</span> = 在第l层，神经单元的个数(不包括偏移量单元)</li>
<li>K = 神经网络输出层的单元个数。就是分类的类别总数。数字识别的话就是10.</li>
</ul>
<p>在Θ矩阵中，列代表当前层的单元个数，包括偏移单元；行代表下一层的神经元个数，不包含偏移单元。</p>
<p>注意：</p>
<ul>
<li>双和嵌套，只是简单的把输出层每个分类的逻辑回归损失加在一起了。m代表训练集的个数。</li>
<li>三个和嵌套的，是把神经网络里面，所有Θ矩阵的元素平方加在一起了。</li>
<li>i在三和嵌套中，代表的不是训练样本个数，而是代表当前层的神经元个数。</li>
</ul>
<h1 id="反向传播算法-backpropagation-algorithm">反向传播算法 Backpropagation Algorithm</h1>
<p>Back propagation的本质就是复合函数求导（following the chain rule）链式法则，本可以对这个网络里的每一个参数分别求偏导，但何苦呢，因为计算过程中的很多项都是重复的。为了不重复运算把把后层算好的导数传回前层，因为前层一定用得到。<br>关于反向传播算法，这里有个<a href="https://www.zhihu.com/question/27239198?rf=24827633" target="_blank" rel="external">浅显易懂的描述</a>。这里请看<a href="http://www.cnblogs.com/dengdan890730/p/5537451.html" target="_blank" rel="external">反向传播算法的推导过程</a>和<a href="http://blog.csdn.net/u014403897/article/details/46347351" target="_blank" rel="external">这里最后一层的求导</a>,这几个地方写的都不错。Andrew Ng老师的公开课对反向传播算法没有做过多的介绍，讲的也不够清晰。反向传播算法，就是为了计算损失函数的导数。<br>先贴个图片留作记号，便于下面Δ计算的理解</p>
<div class="figure">
<img src="/media/14939758124978.jpg">

</div>
<h2 id="反向传播算法的使用过程">反向传播算法的使用过程：</h2>
<ol style="list-style-type: decimal">
<li>Set <span class="math">\(a^{(1)} := x^{(t)}\)</span></li>
<li><p>正向计算每层的每个节点的<span class="math">\(a^{(l)}\)</span>for l=2,3,…,L</p>
<div class="figure">
<img src="/media/14939747131225.jpg">

</div></li>
<li>使用<span class="math">\(y^{(t)}，计算出\delta^{(L)} = a^{(L)} - y^{(t)}\)</span>，最后输出层的错误率。</li>
<li><p>使用<span class="math">\(\delta^{(l)} = ((\Theta^{(l)})^T \delta^{(l+1)})\ .*\ a^{(l)}\ .*\ (1 - a^{(l)})\)</span>，计算出<span class="math">\(\delta^{(L-1)}, \delta^{(L-2)},\dots,\delta^{(2)}\)</span>。<br> 其中$g’(z^{(l)}) = a^{(l)} .* (1 - a^{(l)})；_j^{(l)} =  cost(t)； $</p></li>
</ol>
<p><span class="math">\(cost(t) =y^{(t)} \ \log (h_\Theta (x^{(t)})) + (1 - y^{(t)})\ \log (1 - h_\Theta(x^{(t)}))\)</span></p>
<ol start="5" style="list-style-type: decimal">
<li><span class="math">\(\Delta^{(l)}_{i,j} := \Delta^{(l)}_{i,j} + a_j^{(l)} \delta_i^{(l+1)}，或者向量化一下，\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^T\)</span>(Δ的初始化为0)<br> 至此，我们更新的权值累加器矩阵的为new Δ matrix，其中<span class="math">\(\frac \partial {\partial \Theta_{ij}^{(l)}} J(\Theta)=D_{ij}^{(l)}\)</span>
<ul>
<li><p><span class="math">\(D^{(l)}_{i,j} := \dfrac{1}{m}\left(\Delta^{(l)}_{i,j} + \lambda\Theta^{(l)}_{i,j}\right)\)</span> if j≠0.</p></li>
<li><p><span class="math">\(D^{(l)}_{i,j} := \dfrac{1}{m}\Delta^{(l)}_{i,j}\)</span> If j=0</p></li>
</ul></li>
</ol>
<h3 id="梯度检验">梯度检验</h3>
<p>在神经网络中使用反向传播算法的时候，因为有很多细节，会导致各种各样小bug，即使J看起来每次都是下降的，但是，最终结果的误差却很大。因此梯度检验也是需要的过程，它减少这种错误的概率。在其他比较复杂的模型中使用梯度算法的时候，进行这种检查也是有意义的，这么做，将会对模型更加自信，确信模型是100%正确。<br><span class="math">\(\dfrac{\partial}{\partial\Theta_j}J(\Theta) \approx \dfrac{J(\Theta_1, \dots, \Theta_j + \epsilon, \dots, \Theta_n) - J(\Theta_1, \dots, \Theta_j - \epsilon, \dots, \Theta_n)}{2\epsilon}\)</span></p>
<p>在确定算法无误后，真正执行学习算法前，一定要关掉梯度检验，否则会很慢的哟。</p>
<h3 id="θ的初始化">Θ的初始化</h3>
<p>Θ初始化在逻辑回归的时候是可以为0的，但是在神经网络中不可以全部为0的。因为都为0的时候，隐藏层的结果都是一样的，这样做，隐藏层就完全是冗余的，神经网络就没作用了，完全就是个逻辑回归。所以我们需要打破对称，随机初始化。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="niuoo" />
          <p class="site-author-name" itemprop="name">niuoo</p>
          <p class="site-description motion-element" itemprop="description">It is my Blog!</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">28</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">niuoo</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
